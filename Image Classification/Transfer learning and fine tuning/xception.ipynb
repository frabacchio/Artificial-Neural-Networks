{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"xception.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"eW5mFaiyurvR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606147807218,"user_tz":-60,"elapsed":36133,"user":{"displayName":"Francesco Bacchiocchi","photoUrl":"","userId":"10647622715432437872"}},"outputId":"349fa8e4-cd01-4b8e-9e5a-68f2b3ddf93a"},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","from google.colab import drive\n","# Set the seed for random operations. \n","# This let our experiments to be reproducible. \n","SEED=1234\n","tf.random.set_seed(SEED)\n","\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","drive.mount('/content/drive')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QnpU3TIPvMrC"},"source":["#cwd='/content/drive/My Drive/Kaggle1'\n","cwd='/content/drive/My Drive/AN2DL'\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.xception import preprocess_input \n","\n","\n","apply_data_augmentation = True\n","\n","# Create training ImageDataGenerator object\n","if apply_data_augmentation:\n","    train_data_gen = ImageDataGenerator(rotation_range=10,\n","                                        width_shift_range=10,\n","                                        height_shift_range=10,\n","                                        zoom_range=0.3,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True,\n","                                        fill_mode='constant',\n","                                        cval=0,\n","                                        preprocessing_function=preprocess_input,\n","                                        validation_split=0.2)\n","else:\n","    train_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                        validation_split=0.2) # set validation split\n","\n","#the validation data generator\n","valid_data_gen = ImageDataGenerator(preprocessing_function=preprocess_input,validation_split=0.2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"il9D47wbvmac","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606148106069,"user_tz":-60,"elapsed":4254,"user":{"displayName":"Francesco Bacchiocchi","photoUrl":"","userId":"10647622715432437872"}},"outputId":"2d789ad3-7819-407f-a966-3b37115751c3"},"source":["#dataset_dir='/content/drive/My Drive/Kaggle1/MaskDataset'\n","dataset_dir='/content/drive/My Drive/AN2DL/MaskDataset'\n","train_dir=os.path.join(dataset_dir,'training')\n","valid_dir=os.path.join(dataset_dir,'training')\n","test_dir=os.path.join(dataset_dir,'test')\n","\n","bs=10\n","\n","# img shape\n","img_h = 512\n","img_w = 512\n","train_generator = train_data_gen.flow_from_directory(\n","    train_dir,\n","    target_size=(img_h,img_w),\n","    batch_size=bs,\n","    class_mode='categorical', # targets are directly converted into one-hot vectors\n","    shuffle=True,seed=SEED,\n","    subset='training') # set as training data\n","\n","validation_generator = train_data_gen.flow_from_directory(\n","    valid_dir, # same directory as training data\n","    target_size=(img_h,img_w),\n","    batch_size=bs,\n","    class_mode='categorical',\n","    subset='validation') # set as validation data\n","\n","\n","#train_generator.class_indices\n","num_classes=len(train_generator.class_indices)\n","\n","train_dataset=tf.data.Dataset.from_generator(lambda:train_generator,output_types=(tf.float32,tf.float32),output_shapes=([None,img_h,img_w,3],[None,num_classes]))\n","train_dataset = train_dataset.repeat()\n","\n","\n","valid_dataset=tf.data.Dataset.from_generator(lambda:validation_generator,output_types=(tf.float32,tf.float32),output_shapes=([None,img_h,img_w,3],[None,num_classes]))\n","valid_dataset=valid_dataset.repeat()\n","iter(train_dataset)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 4492 images belonging to 3 classes.\n","Found 1122 images belonging to 3 classes.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x7fce404c0828>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"nry6sXzRwY6j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606148145753,"user_tz":-60,"elapsed":6438,"user":{"displayName":"Francesco Bacchiocchi","photoUrl":"","userId":"10647622715432437872"}},"outputId":"dd2863f3-dfb7-4fab-dd9f-43924fc63d34"},"source":["#check\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","iterator=iter(train_dataset)\n","augmented_img,target=next(iterator)\n","augmented_img=np.array(augmented_img[0])*255 # denormalize\n","\n","#plt.imshow(np.uint8(augmented_img))\n","#plt.show()\n","iterator"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x7fce4061ac18>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"mbnfqZBUwahG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605879694850,"user_tz":-60,"elapsed":2635,"user":{"displayName":"Francesco Bacchiocchi","photoUrl":"","userId":"10647622715432437872"}},"outputId":"d8cd962b-7326-4ef0-b809-983bfc20040e"},"source":["#import pretrained model without FC part\n","xception = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=(img_h, img_w, 3))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tj-sAiYS4uJS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605879697063,"user_tz":-60,"elapsed":1080,"user":{"displayName":"Francesco Bacchiocchi","photoUrl":"","userId":"10647622715432437872"}},"outputId":"08503be4-3789-40bf-bf03-9d72e7bb1374"},"source":["# Create Model\n","# ------------\n","\n","finetuning = True\n","\n","if finetuning:\n","    freeze_until = 40 # layer from which we want to fine-tune\n","    \n","    for layer in xception.layers[:freeze_until]:\n","        layer.trainable = False\n","else:\n","    xception.trainable = False\n","    \n","model = tf.keras.Sequential()\n","model.add(xception)\n","model.add(tf.keras.layers.GlobalMaxPooling2D(data_format=None))\n","model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n","model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n","\n","# Visualize created model as a table\n","model.summary()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","xception (Functional)        (None, 25, 25, 2048)      20861480  \n","_________________________________________________________________\n","global_max_pooling2d (Global (None, 2048)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 32)                65568     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 3)                 99        \n","=================================================================\n","Total params: 20,927,147\n","Trainable params: 19,227,867\n","Non-trainable params: 1,699,280\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z0pL8av9xVA5"},"source":["# Optimization params\n","# -------------------\n","\n","# Loss\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","\n","# learning rate\n","lr = 1e-4\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","# -------------------\n","\n","# Validation metrics\n","# ------------------\n","\n","metrics = ['accuracy']\n","# ------------------\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nEy93QyUyM0a"},"source":["# Early Stopping\n","# --------------\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,restore_best_weights=True)\n","    callbacks.append(es_callback)\n","\n","# Learning rate adapter \n","# --------------\n","lr_adapter = True\n","if lr_adapter:\n","    lr_adapter_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, mode='auto', min_delta=0.0001, cooldown=0,restore_best_weights=True)\n","    callbacks.append(lr_adapter_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ddyPgJkOyr51","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605896193863,"user_tz":-60,"elapsed":16475124,"user":{"displayName":"Francesco Bacchiocchi","photoUrl":"","userId":"10647622715432437872"}},"outputId":"3d09b591-edf2-41fd-a05f-6c40e9925795"},"source":["#model training\n","model.fit(x=train_dataset,\n","          epochs=50, \n","          steps_per_epoch=len(train_generator)/2,\n","          validation_data=valid_dataset,\n","          validation_steps=len(validation_generator), \n","          callbacks=callbacks)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","225/225 [==============================] - 1574s 7s/step - loss: 0.5854 - accuracy: 0.7253 - val_loss: 0.2909 - val_accuracy: 0.8779\n","Epoch 2/50\n","225/225 [==============================] - 1216s 5s/step - loss: 0.2723 - accuracy: 0.8898 - val_loss: 0.2840 - val_accuracy: 0.8806\n","Epoch 3/50\n","225/225 [==============================] - 593s 3s/step - loss: 0.2033 - accuracy: 0.9267 - val_loss: 0.1981 - val_accuracy: 0.9225\n","Epoch 4/50\n","225/225 [==============================] - 592s 3s/step - loss: 0.1670 - accuracy: 0.9384 - val_loss: 0.2461 - val_accuracy: 0.9251\n","Epoch 5/50\n","225/225 [==============================] - 605s 3s/step - loss: 0.1509 - accuracy: 0.9467 - val_loss: 0.1351 - val_accuracy: 0.9519\n","Epoch 6/50\n","225/225 [==============================] - 626s 3s/step - loss: 0.1261 - accuracy: 0.9599 - val_loss: 0.1812 - val_accuracy: 0.9340\n","Epoch 7/50\n","225/225 [==============================] - 628s 3s/step - loss: 0.1081 - accuracy: 0.9649 - val_loss: 0.1444 - val_accuracy: 0.9528\n","Epoch 8/50\n","225/225 [==============================] - 610s 3s/step - loss: 0.1146 - accuracy: 0.9612 - val_loss: 0.2597 - val_accuracy: 0.9144\n","Epoch 9/50\n","225/225 [==============================] - 608s 3s/step - loss: 0.0937 - accuracy: 0.9662 - val_loss: 0.1580 - val_accuracy: 0.9421\n","Epoch 10/50\n","225/225 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.9603\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n","225/225 [==============================] - 593s 3s/step - loss: 0.1084 - accuracy: 0.9603 - val_loss: 0.1362 - val_accuracy: 0.9519\n","Epoch 11/50\n","225/225 [==============================] - 605s 3s/step - loss: 0.0512 - accuracy: 0.9849 - val_loss: 0.1322 - val_accuracy: 0.9590\n","Epoch 12/50\n","225/225 [==============================] - 614s 3s/step - loss: 0.0636 - accuracy: 0.9781 - val_loss: 0.1295 - val_accuracy: 0.9617\n","Epoch 13/50\n","225/225 [==============================] - 619s 3s/step - loss: 0.0467 - accuracy: 0.9849 - val_loss: 0.1559 - val_accuracy: 0.9563\n","Epoch 14/50\n","225/225 [==============================] - 633s 3s/step - loss: 0.0430 - accuracy: 0.9848 - val_loss: 0.1072 - val_accuracy: 0.9688\n","Epoch 15/50\n","225/225 [==============================] - 619s 3s/step - loss: 0.0349 - accuracy: 0.9871 - val_loss: 0.1453 - val_accuracy: 0.9572\n","Epoch 16/50\n","225/225 [==============================] - 621s 3s/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 0.1599 - val_accuracy: 0.9626\n","Epoch 17/50\n","225/225 [==============================] - 628s 3s/step - loss: 0.0532 - accuracy: 0.9818 - val_loss: 0.1430 - val_accuracy: 0.9572\n","Epoch 18/50\n","225/225 [==============================] - 630s 3s/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.1455 - val_accuracy: 0.9635\n","Epoch 19/50\n","225/225 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9911\n","Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n","225/225 [==============================] - 629s 3s/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.1407 - val_accuracy: 0.9643\n","Epoch 20/50\n","225/225 [==============================] - 643s 3s/step - loss: 0.0445 - accuracy: 0.9880 - val_loss: 0.1615 - val_accuracy: 0.9617\n","Epoch 21/50\n","225/225 [==============================] - 626s 3s/step - loss: 0.0384 - accuracy: 0.9898 - val_loss: 0.1395 - val_accuracy: 0.9643\n","Epoch 22/50\n","225/225 [==============================] - 631s 3s/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.1498 - val_accuracy: 0.9643\n","Epoch 23/50\n","225/225 [==============================] - 636s 3s/step - loss: 0.0296 - accuracy: 0.9907 - val_loss: 0.1583 - val_accuracy: 0.9572\n","Epoch 24/50\n","225/225 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9924\n","Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n","225/225 [==============================] - 631s 3s/step - loss: 0.0324 - accuracy: 0.9924 - val_loss: 0.1316 - val_accuracy: 0.9661\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f2090a2fc18>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"ccwg7AUYRN1I"},"source":["model.save('/content/drive/My Drive/Kaggle1/TransferSavedModel/xception_final')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mzg9g5AXyx2X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605634705177,"user_tz":-60,"elapsed":123427,"user":{"displayName":"Francesco Bacchiocchi","photoUrl":"","userId":"10647622715432437872"}},"outputId":"50b9c2f5-2083-4e40-ef6f-dc95c9eb8f3d"},"source":["#evaluate optimal weights on validation set\n","val=model.evaluate(valid_dataset,steps=len(validation_generator),verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["113/113 [==============================] - 121s 1s/step - loss: 0.1850 - accuracy: 0.9501\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9Qa3oJzIdN-k"},"source":["#compute predictions\n","from PIL import Image\n","\n","final_path = os.path.join(dataset_dir, 'test')\n","image_filenames = next(os.walk(final_path))[2] \n","\n","results={} \n","for image_name in image_filenames:\n","  \n","   img=Image.open(final_path+'/'+image_name).convert('RGB')\n","   img=img.resize((img_h,img_w))\n","   img_array=np.array(img)\n","   img_array=preprocess_input(img_array)\n","   img_array=np.expand_dims(img_array, 0)\n","   pred=model.predict(img_array)\n","   prediction=np.argmax(pred)\n","   results[image_name]=prediction"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mC6KDRuXzQ6D"},"source":["def create_csv(results, results_dir='./'):\n","\n","    csv_fname = 'xception'\n","    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n","\n","    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n","\n","        f.write('Id,Category\\n')\n","\n","        for key, value in results.items():\n","            f.write(key + ',' + str(value)+ '\\n')\n","create_csv(results,cwd)"],"execution_count":null,"outputs":[]}]}