{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Basic_model.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t4m1NWHVJmje","executionInfo":{"status":"ok","timestamp":1608046463206,"user_tz":-60,"elapsed":24796,"user":{"displayName":"Fabio Menozzi","photoUrl":"","userId":"17453204346991109173"}},"outputId":"8d849e9a-9d98-42a3-e2d9-c44abe6af878"},"source":["from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\"\n","\n","import os\n","import tensorflow as tf\n","import numpy as np\n","\n","# Set the seed for random operations. \n","# This let our experiments to be reproducible. \n","SEED = 1234\n","tf.random.set_seed(SEED)  \n","\n","cwd = os.getcwd()\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lCAUzGL7GFus"},"source":["#here we use original size images\n","\n","#Creation of the dataset for Haricot model\n","\n","#!mkdir -p '/content/drive/My Drive/Kaggle2/Training/Bipbip/Haricot/Images/img'\n","#!mkdir -p '/content/drive/My Drive/Kaggle2/Training/Bipbip/Haricot/Masks/img'\n","\n","\n","#!cp '/content/drive/My Drive/Kaggle2/Development_Dataset/Training/Bipbip/Haricot/Images/* '/content/drive/My Drive/Kaggle2/Training/Bipbip/Haricot/Images/img'\n","#!cp /content/drive/My Drive/Kaggle2/Development_Dataset/Training/Bipbip/Haricot/Masks/* '/content/drive/My Drive/Kaggle2/Training/Bipbip/Haricot/Masks/img'\n","\n","\n","#Creation of the dataset for Mais model\n","!mkdir -p '/content/drive/My Drive/Kaggle2/Training/Bipbip/Mais/Images/img'\n","!mkdir -p '/content/drive/My Drive/Kaggle2/Training/Bipbip/Mais/Masks/img'\n","\n","\n","\n","!cp /content/drive/My Drive/Kaggle2/Development_Dataset/Training/Bipbip/Mais/Images/* '/content/drive/My Drive/Kaggle2/Training/Bipbip/Mais/Images/img'\n","!cp /content/drive/My Drive/Kaggle2/Development_Dataset/Training/Bipbip/Mais/Masks/* '/content/drive/My Drive/Kaggle2/Training/Bipbip/Mais/Masks/img'\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFHrtOWRJxDP"},"source":["# ImageDataGenerator\n","# ------------------\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","apply_data_augmentation = True\n","\n","# Create training ImageDataGenerator object\n","# We need two different generators for images and corresponding masks\n","if apply_data_augmentation:\n","    train_img_data_gen = ImageDataGenerator(rotation_range=10,\n","                                      width_shift_range=10,\n","                                      height_shift_range=10,\n","                                      zoom_range=0.3,\n","                                      horizontal_flip=True,\n","                                      vertical_flip=True,\n","                                      fill_mode='reflect',\n","                                      rescale=1./255,\n","                                      validation_split=0.2)\n","    train_mask_data_gen = ImageDataGenerator(rotation_range=10,\n","                                       width_shift_range=10,\n","                                       height_shift_range=10,\n","                                       zoom_range=0.3,\n","                                       horizontal_flip=True,\n","                                       vertical_flip=True,\n","                                       fill_mode='reflect',\n","                                       validation_split=0.2)\n","else:\n","    train_img_data_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n","    train_mask_data_gen = ImageDataGenerator(validation_split=0.2)\n","\n","# Create validation ImageDataGenerator objects\n","valid_img_data_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n","valid_mask_data_gen = ImageDataGenerator(validation_split=0.2)\n","\n","# Create generators to read images from dataset directory\n","# -------------------------------------------------------\n","#dataset_dir = os.path.join(cwd, 'Development_Dataset')\n","dataset_dir = '/content/drive/My Drive/Kaggle2/Training/Bipbip'\n","# Batch size\n","bs = 4\n","\n","# img shape bipbip\n","img_h = 1536\n","img_w = 2048\n","num_classes=3\n","\n","# Training\n","# Two different generators for images and masks but with same seed\n","training_dir = os.path.join(dataset_dir, 'Mais')  #put 'Haricot' for the other model\n","train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'Images'),\n","                                                       target_size=(img_h, img_w),\n","                                                       batch_size=bs,\n","                                                       class_mode=None, \n","                                                       shuffle=True,\n","                                                       interpolation='bilinear',\n","                                                       seed=SEED,\n","                                                       subset='training')  \n","train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'Masks'),\n","                                                         target_size=(img_h, img_w),\n","                                                         batch_size=bs,\n","                                                         class_mode=None,\n","                                                         shuffle=True,\n","                                                         interpolation='nearest',\n","                                                         seed=SEED,\n","                                                         subset='training')\n","train_gen = zip(train_img_gen, train_mask_gen)\n","\n","# Validation\n","valid_img_gen = valid_img_data_gen.flow_from_directory(os.path.join(training_dir, 'Images'),\n","                                                       target_size=(img_h, img_w),\n","                                                       batch_size=bs, \n","                                                       class_mode=None, \n","                                                       shuffle=False,\n","                                                       interpolation='bilinear',\n","                                                       seed=SEED,\n","                                                       subset='validation')\n","valid_mask_gen = valid_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'Masks'),\n","                                                         target_size=(img_h, img_w),\n","                                                         batch_size=bs, \n","                                                         class_mode=None,\n","                                                         shuffle=False,\n","                                                         interpolation='nearest',\n","                                                         seed=SEED,\n","                                                         subset='validation')\n","valid_gen = zip(valid_img_gen, valid_mask_gen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u7xm26qGKPeP"},"source":["train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None,img_h, img_w, 3], [None,img_h, img_w, 3]))\n","\n","\n","def prepare_target(x_, y_):\n","  # Use RGB dictionary in 'RGBtoTarget.txt' to convert RGB to target labels 256 x 256 x 1\n","  #[254, 124, 18] = 0 done implicitly with the first cast\n","  #[255, 255, 255]= 1 done with the first cast\n","  #[216, 67, 82]= 2 done with the second cast that is multiplied by 2\n","    output=tf.cast(tf.reduce_all(y_== [255, 255, 255], axis=-1, keepdims=True), tf.float32)\n","    output=output+2*tf.cast(tf.reduce_all(y_== [216, 67, 82], axis=-1, keepdims=True), tf.float32)\n","    return x_, output\n","\n","train_dataset = train_dataset.map(prepare_target)\n","\n","\n","train_dataset = train_dataset.repeat()\n","\n","valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n","                                               output_types=(tf.float32, tf.float32),\n","                                               output_shapes=([None,img_h, img_w, 3], [None,img_h, img_w,3]))\n","valid_dataset = valid_dataset.map(prepare_target)\n","\n","\n","valid_dataset = valid_dataset.repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dv_bthKnKR-a"},"source":["# Let's test data generator for a check\n","# -------------------------\n","import time\n","from matplotlib import cm\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","\n","# Assign a color to each class\n","evenly_spaced_interval = np.linspace(0, 1, num_classes-1)\n","colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n","\n","iterator = iter(train_dataset)\n","\n","fig, ax = plt.subplots(1, 2)\n","\n","augmented_img, target = next(iterator)\n","augmented_img = np.array(augmented_img[0])   # First element\n","augmented_img = augmented_img *255           # denormalize\n","\n","target = np.array(target[0, ..., 0])         # First element (squeezing channel dimension)\n","print(np.unique(target))\n","\n","target_img = np.zeros([target.shape[0], target.shape[1], 3])\n","\n","target_img[np.where(target == 0)] = [0, 0, 0]\n","for i in range(1, num_classes):\n","  target_img[np.where(target == i)] = np.array(colors[i-1])[:3] * 255\n","\n","ax[0].imshow(np.uint8(augmented_img))\n","ax[1].imshow(np.uint8(target_img))\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZO9Mcj2KrkhN"},"source":["# Create Model\n","# ------------\n","\n","def create_model(depth, start_f, dynamic_input_shape):\n","\n","    model = tf.keras.Sequential()\n","    \n","    # Encoder\n","    # -------\n","    for i in range(depth):\n","        \n","        if i == 0:\n","            if dynamic_input_shape:\n","                input_shape = [None, None, 3]\n","            else:\n","                input_shape = [img_h, img_w, 3]\n","        else:\n","            input_shape=[None]\n","        \n","        model.add(tf.keras.layers.Conv2D(filters=start_f, \n","                                         kernel_size=(3, 3),\n","                                         strides=(1, 1),\n","                                         padding='same',\n","                                         input_shape=input_shape))\n","        model.add(tf.keras.layers.ReLU())\n","        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","\n","        start_f *= 2\n","\n","    # Bottleneck\n","    model.add(tf.keras.layers.Conv2D(filters=start_f, kernel_size=(3, 3), strides=(1, 1), padding='same'))\n","    model.add(tf.keras.layers.ReLU())\n","    \n","    start_f = start_f // 2\n","        \n","    # Decoder\n","    # -------\n","    for i in range(depth):\n","        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n","        model.add(tf.keras.layers.Conv2D(filters=start_f,\n","                                         kernel_size=(3, 3),\n","                                         strides=(1, 1),\n","                                         padding='same'))\n","        model.add(tf.keras.layers.ReLU())\n","\n","        start_f = start_f // 2\n","\n","    # Prediction Layer\n","    # ----------------\n","    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n","                                     kernel_size=(1, 1),\n","                                     strides=(1, 1),\n","                                     padding='same',\n","                                     activation='softmax'))\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZNbVakXlrxnK"},"source":["model= create_model(depth=6, \n","                    start_f=16,\n","                    dynamic_input_shape=True)\n","# Visualize created model as a table\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXx4Ipp0r95S"},"source":["# Optimization params\n","# -------------------\n","\n","# Loss\n","# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n","loss = tf.keras.losses.SparseCategoricalCrossentropy() \n","# learning rate\n","lr = 1e-3\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","# -------------------\n","\n","# Here we define the intersection over union for each class in the batch.\n","# Then we compute the final iou as the mean over classes\n","def meanIoU(y_true, y_pred):\n","    # get predicted class from softmax\n","    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n","\n","    per_class_iou = []\n","\n","    for i in range(1,3): # exclude the background class 0\n","      # Get prediction and target related to only a single class (i)\n","      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n","      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n","      intersection = tf.reduce_sum(class_true * class_pred)\n","      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n","    \n","      iou = (intersection + 1e-7) / (union + 1e-7)\n","      per_class_iou.append(iou)\n","\n","    return tf.reduce_mean(per_class_iou)\n","\n","# Validation metrics\n","# ------------------\n","metrics = ['accuracy', meanIoU]\n","# ------------------\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cYcUTu-sGaT"},"source":["#callbacks for training  \n","callbacks = []\n","\n","# Early Stopping\n","# --------------\n","early_stop = True\n","if early_stop:\n","    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n","    callbacks.append(es_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOxUAu4BsJ5T"},"source":["#training\n","model.fit(x=train_dataset,\n","          epochs=50,  \n","          steps_per_epoch=len(train_img_gen ),\n","          validation_data=valid_dataset,\n","          validation_steps=len(valid_img_gen ), \n","          callbacks=callbacks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cFYVxZj6rrC"},"source":["#saving the model for final ensembling\n","model.save('/content/drive/My Drive/Kaggle2/SavedModel/basic_mais.h5') \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqjBZcJVTHWa"},"source":["#loading models for predictions\n","\n","def meanIoU(y_true, y_pred):\n","    # get predicted class from softmax\n","    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n","\n","    per_class_iou = []\n","\n","    for i in range(1,3): # exclude the background class 0\n","      # Get prediction and target related to only a single class (i)\n","      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n","      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n","      intersection = tf.reduce_sum(class_true * class_pred)\n","      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n","    \n","      iou = (intersection + 1e-7) / (union + 1e-7)\n","      per_class_iou.append(iou)\n","\n","    return tf.reduce_mean(per_class_iou)\n","\n","\n","model_haricot=tf.keras.models.load_model('/content/drive/My Drive/Kaggle2/SavedModel/basic_haricot.h5',custom_objects={'meanIoU':meanIoU})\n","\n","model_mais=tf.keras.models.load_model('/content/drive/My Drive/Kaggle2/SavedModel/basic_mais.h5',custom_objects={'meanIoU':meanIoU})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3tFf5EsxE3OD"},"source":["# prepare submission\n","\n","from PIL import Image\n","def rle_encode(img):\n","    '''\n","    img: numpy array, 1 - foreground, 0 - background\n","    Returns run length as string formatted\n","    '''\n","    pixels = img.flatten()\n","    pixels = np.concatenate([[0], pixels, [0]])\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","    runs[1::2] -= runs[::2]\n","    return ' '.join(str(x) for x in runs)\n","\n","submission_dict = {}\n","groups=['Bipbip','Pead','Roseau','Weedelec']\n","hm=['Haricot','Mais']\n","for g in groups:\n","  for h in hm:\n","      final_path = '/content/drive/My Drive/Kaggle2/Test_Dev/'+ str(g) + '/'+ str(h) +'/Images'\n","      image_filenames = next(os.walk(final_path))[2]   \n","      for img_name in image_filenames:\n","          img=Image.open(final_path+'/'+img_name).convert('RGB')\n","          img_array=np.array(img)/255\n","          if h=='Mais':\n","              out_sigmoid = model_mais.predict(x=tf.expand_dims(img_array, 0))\n","          else:\n","              out_sigmoid = model_haricot.predict(x=tf.expand_dims(img_array, 0))\n","          predicted_class = tf.argmax(out_sigmoid, -1)\n","          predicted_class = predicted_class[0, ...]\n","          mask_arr = np.array(predicted_class)\n","          # RLE encoding\n","          # crop\n","          rle_encoded_crop = rle_encode(mask_arr == 1)\n","          # weed\n","          rle_encoded_weed = rle_encode(mask_arr == 2)\n","          img_name_without_extension=img_name[:-4]\n","          submission_dict[img_name_without_extension] = {}\n","          submission_dict[img_name_without_extension]['shape'] = mask_arr.shape\n","          submission_dict[img_name_without_extension]['team'] = g\n","          submission_dict[img_name_without_extension]['crop'] = h\n","          submission_dict[img_name_without_extension]['segmentation'] = {}\n","          submission_dict[img_name_without_extension]['segmentation']['crop'] = rle_encoded_crop\n","          submission_dict[img_name_without_extension]['segmentation']['weed'] = rle_encoded_weed\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKUPJBza78lA"},"source":["# save submission\n","import json\n","with open('/content/drive/My Drive/Kaggle2/finale_basic_submission.json', 'w') as f:\n","  json.dump(submission_dict, f)"],"execution_count":null,"outputs":[]}]}